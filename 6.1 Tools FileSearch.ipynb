{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-BW8h92v4RKLxiBcaJGJ4ix\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def create_file(client, file_path):\n",
    "    if file_path.startswith(\"http://\") or file_path.startswith(\"https://\"):\n",
    "        # Download the file content from the URL\n",
    "        response = requests.get(file_path)\n",
    "        file_content = BytesIO(response.content)\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_tuple = (file_name, file_content)\n",
    "        result = client.files.create(\n",
    "            file=file_tuple,\n",
    "            purpose=\"assistants\"\n",
    "        )\n",
    "    else:\n",
    "        # Handle local file path\n",
    "        with open(file_path, \"rb\") as file_content:\n",
    "            result = client.files.create(\n",
    "                file=file_content,\n",
    "                purpose=\"assistants\"\n",
    "            )\n",
    "    print(result.id)\n",
    "    return result.id\n",
    "\n",
    "# Replace with your own file path or URL\n",
    "file_id = create_file(client, \"https://cdn.openai.com/API/docs/deep_research_blog.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-BW8h92v4RKLxiBcaJGJ4ix'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_67d1bdb576788191841b2bd18b054d42\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "    name=\"knowledge_base\"\n",
    ")\n",
    "print(vector_store.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStoreFile(id='file-BW8h92v4RKLxiBcaJGJ4ix', created_at=1741798865, last_error=None, object='vector_store.file', status='in_progress', usage_bytes=0, vector_store_id='vs_67d1bdb576788191841b2bd18b054d42', attributes={}, chunking_strategy=StaticFileChunkingStrategyObject(static=StaticFileChunkingStrategy(chunk_overlap_tokens=400, max_chunk_size_tokens=800), type='static'))\n"
     ]
    }
   ],
   "source": [
    "result=client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store.id,\n",
    "    file_id=file_id\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, FileSearchTool, Runner, WebSearchTool\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    tools=[\n",
    "        WebSearchTool(),\n",
    "         FileSearchTool(\n",
    "            max_num_results=3,\n",
    "            vector_store_ids=[vector_store.id],\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    result = await Runner.run(agent, \"what is prerequisite for creating new knowledge\")\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prerequisite for creating new knowledge is the ability to synthesize existing knowledge. This involves reasoning, analyzing, and consolidating information from various sources, which is crucial for developing insights that lead to the creation of novel research.\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
